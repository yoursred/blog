---
layout: post
title: ""
visible: false
---

_This will be the first of many articles sharing my view on artificial intelligence and where it is today._

Ahh students, beloved by few and exploited by most. But in no other way, at this scale, in recent times: "artificial intelligence" or AI in marketing. Mind you, tools for students have been a dime a dozen on the internet ever since its creation, they made the damn thing. Tools to help you write better (or worse), math solvers that give detailed step-by-step solutions, and even [personalized quizzes] here and there.

## The colossal elephant in the room

These tools have been generally harmless, if not productive, they won't necessarily be the focus of this little writeup. You know it, you've seen it, and you've probably used at least once in your life: ChatGPT (and friends). Why spend time and resources creating and using purpose-built tools, why ask a real human being for help, why think for yourself; large language models (LLMs) are here to save the day! And early on they seemed like neat little additions whose accumulative gain in productivity would breathe fresh air into everyone's [otherwise average/mundane] lives. If that were the end of it, I woudn't be complaining here. Unfortunately, we just can't have nice things.

I have the most resentment for AI chatbots, they make it seem like everyone can have their very own Personal Socrates. It has gotten to a point where most students at my university seemingly depend on them, often to their detriment. Students put far too much trust in them, creating an ouroboros of utter shit. Let me paint for you a less graphic scenario:
### A student is [revising and practicing]
> *Student, after attempting a question*: Can you check my answer?
>
> *GPT*: Hmm, it looks like you got this part wrong. Here's how it should be.
>
> *Student, unsure themselves of both answers*: Shouldn't it be like this?
>
> *GPT, wired to oblige*: My dearest of apologies, it should indeed be like that.
>
> *Student, after checking solutions


I have seen the previous exchange or versions of it far too often, yet students are still incessant on trusting the chat bot. And I believe I may have an idea why that's the case: the [human] element. We are social creatures afterall, and we tend to value and appreciate human interaction. The problem here is the lack of human interaction, you're talking to a machine that can consistenly hallucinate on command and not much more than that. Of course they don't know any better and just